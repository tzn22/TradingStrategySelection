{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e2d58b9",
   "metadata": {},
   "source": [
    "\n",
    "# SAC Market-Neutral Training Notebook\n",
    "\n",
    "**Описание:** этот ноутбук реализует стратегию *market-neutral* на данных DOW30 в 1‑минутном таймфрейме.\n",
    "Агент: **SAC (Soft Actor-Critic)**. Окружение — модифицированное FinRL-style `TradingEnv` с комиссией, слиппеджем,\n",
    "штрафом за net exposure и reward в виде Sharpe‑proxy (rolling). Также реализован walk-forward (rolling) pipeline.\n",
    "\n",
    "**Что делает ноутбук:**\n",
    "1. Загружает данные (путь указывается в `DATA_PATH`).\n",
    "2. Делает базовые фичи (returns, MA, z-score, realized vol, VIX/turbulence если есть).\n",
    "3. Создаёт векторизуемое окружение `MarketNeutralEnv` (continuous actions: target weights per asset).\n",
    "4. Тренирует SAC в walk-forward режиме и сохраняет модели и метрики.\n",
    "\n",
    "**Примечания:** установите необходимые зависимости (`stable-baselines3`, `gym`, `pandas`, `numpy`, `matplotlib`, `ta` и т.д.).\n",
    "Если используешь собственные датасеты/файлы/окружения — подправь пути и части кода. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "424c9c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: alpaca_trade_api in c:\\users\\cody\\anaconda3\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: pandas>=0.18.1 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from alpaca_trade_api) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.11.1 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from alpaca_trade_api) (2.1.3)\n",
      "Requirement already satisfied: requests<3,>2 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from alpaca_trade_api) (2.32.3)\n",
      "Requirement already satisfied: urllib3<2,>1.24 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from alpaca_trade_api) (1.26.20)\n",
      "Requirement already satisfied: websocket-client<2,>=0.56.0 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from alpaca_trade_api) (1.8.0)\n",
      "Requirement already satisfied: websockets<11,>=9.0 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from alpaca_trade_api) (10.4)\n",
      "Requirement already satisfied: msgpack==1.0.3 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from alpaca_trade_api) (1.0.3)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.3 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from alpaca_trade_api) (3.11.10)\n",
      "Requirement already satisfied: PyYAML==6.0.1 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from alpaca_trade_api) (6.0.1)\n",
      "Requirement already satisfied: deprecation==2.1.0 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from alpaca_trade_api) (2.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\cody\\anaconda3\\lib\\site-packages (from deprecation==2.1.0->alpaca_trade_api) (24.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.3->alpaca_trade_api) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.3->alpaca_trade_api) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.3->alpaca_trade_api) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.3->alpaca_trade_api) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.3->alpaca_trade_api) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.3->alpaca_trade_api) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.3->alpaca_trade_api) (1.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from requests<3,>2->alpaca_trade_api) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from requests<3,>2->alpaca_trade_api) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from requests<3,>2->alpaca_trade_api) (2025.11.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from pandas>=0.18.1->alpaca_trade_api) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from pandas>=0.18.1->alpaca_trade_api) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from pandas>=0.18.1->alpaca_trade_api) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.18.1->alpaca_trade_api) (1.17.0)\n",
      "Requirement already satisfied: stable_baselines3 in c:\\users\\cody\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from stable_baselines3) (1.2.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from stable_baselines3) (2.1.3)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from stable_baselines3) (2.9.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\cody\\anaconda3\\lib\\site-packages (from stable_baselines3) (3.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\cody\\anaconda3\\lib\\site-packages (from stable_baselines3) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\cody\\anaconda3\\lib\\site-packages (from stable_baselines3) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\cody\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable_baselines3) (3.17.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable_baselines3) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cody\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable_baselines3) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from pandas->stable_baselines3) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from pandas->stable_baselines3) (2025.2)\n",
      "Requirement already satisfied: gymnasium in c:\\users\\cody\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from gymnasium) (2.1.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from gymnasium) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from gymnasium) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: ta in c:\\users\\cody\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\cody\\anaconda3\\lib\\site-packages (from ta) (2.1.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\cody\\anaconda3\\lib\\site-packages (from ta) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from pandas->ta) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from pandas->ta) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from pandas->ta) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
      "Requirement already satisfied: finrl in c:\\users\\cody\\anaconda3\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: stockstats in c:\\users\\cody\\anaconda3\\lib\\site-packages (0.6.5)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from stockstats) (2.1.3)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from stockstats) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->stockstats) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->stockstats) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->stockstats) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->stockstats) (1.17.0)\n",
      "Requirement already satisfied: wrds in c:\\users\\cody\\anaconda3\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: packaging<=24.2 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from wrds) (24.2)\n",
      "Requirement already satisfied: pandas<2.3,>=2.2 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from wrds) (2.2.3)\n",
      "Requirement already satisfied: psycopg2-binary<2.10,>=2.9 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from wrds) (2.9.11)\n",
      "Requirement already satisfied: sqlalchemy<2.1,>=2 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from wrds) (2.0.39)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from pandas<2.3,>=2.2->wrds) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from pandas<2.3,>=2.2->wrds) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from pandas<2.3,>=2.2->wrds) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from pandas<2.3,>=2.2->wrds) (2025.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from sqlalchemy<2.1,>=2->wrds) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from sqlalchemy<2.1,>=2->wrds) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cody\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<2.3,>=2.2->wrds) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install alpaca_trade_api\n",
    "!pip install stable_baselines3\n",
    "!pip install gymnasium\n",
    "!pip install ta\n",
    "!pip install finrl\n",
    "!pip install stockstats\n",
    "!pip install wrds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7b318ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports and basic config\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dill\n",
    "import json\n",
    "from datetime import timedelta\n",
    "\n",
    "# RL libraries\n",
    "try:\n",
    "    from stable_baselines3 import SAC\n",
    "    from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "except Exception as e:\n",
    "    print(\"stable-baselines3 not found. Please install it: pip install stable-baselines3[extra]\")\n",
    "    \n",
    "import gym\n",
    "from gym import spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67686183",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = 'prepared_csv/AAPL_prepared.csv'\n",
    "OUTPUT_DIR = 'results/cas'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "ASSETS = None   # if None, infer from dataframe columns\n",
    "TRAIN_WINDOW_MONTHS = 12\n",
    "VAL_MONTHS = 3\n",
    "TEST_MONTHS = 3\n",
    "\n",
    "# Env / trading params\n",
    "COMMISSION_RATE = 0.0005\n",
    "SLIPPAGE_COEF = 0.0001\n",
    "EXPOSURE_PENALTY = 0.02\n",
    "TURNOVER_PENALTY = 0.001\n",
    "SHARPE_WINDOW = 250  # in timesteps\n",
    "\n",
    "# SAC hyperparams (simple default)\n",
    "SAC_PARAMS = dict(\n",
    "    verbose=1,\n",
    "    learning_rate=3e-4,\n",
    "    buffer_size=200_000,\n",
    "    batch_size=256,\n",
    "    tau=0.005,\n",
    "    gamma=0.995,\n",
    "    train_freq=1,\n",
    ")\n",
    "TOTAL_TIMESTEPS = 1_000_000  # per fold (adjust to compute resources)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b480ac1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cody\\AppData\\Local\\Temp\\ipykernel_35688\\1596087260.py:5: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(path, parse_dates=['date'], infer_datetime_format=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing column provided to 'parse_dates': 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Example expected CSV format:\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# date, ticker, open, high, low, close, volume, vix, turbulence\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Use multi-asset long format (row per asset per timestamp).\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded data rows:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df))\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Detect asset list\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData file not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please place CSV with 1-min DOW30 data there.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfer_datetime_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\cody\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cody\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\cody\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cody\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\cody\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:161\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_usecols_names(\n\u001b[0;32m    156\u001b[0m             usecols,\n\u001b[0;32m    157\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    158\u001b[0m         )\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_parse_dates_presence\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_noconvert_columns()\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cody\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:243\u001b[0m, in \u001b[0;36mParserBase._validate_parse_dates_presence\u001b[1;34m(self, columns)\u001b[0m\n\u001b[0;32m    233\u001b[0m missing_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m    235\u001b[0m         {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    240\u001b[0m     )\n\u001b[0;32m    241\u001b[0m )\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_cols:\n\u001b[1;32m--> 243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing column provided to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_dates\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    245\u001b[0m     )\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# Convert positions to actual column names\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    248\u001b[0m     col \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns) \u001b[38;5;28;01melse\u001b[39;00m columns[col]\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols_needed\n\u001b[0;32m    250\u001b[0m ]\n",
      "\u001b[1;31mValueError\u001b[0m: Missing column provided to 'parse_dates': 'date'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data loading and basic preprocessing\n",
    "def load_data(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Data file not found at {path}. Please place CSV with 1-min DOW30 data there.\")\n",
    "    df = pd.read_csv(path, parse_dates=['date'], infer_datetime_format=True)\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Example expected CSV format:\n",
    "# date, ticker, open, high, low, close, volume, vix, turbulence\n",
    "# Use multi-asset long format (row per asset per timestamp).\n",
    "df = load_data(DATA_PATH)\n",
    "print(\"Loaded data rows:\", len(df))\n",
    "# Detect asset list\n",
    "if ASSETS is None:\n",
    "    ASSETS = df['tic'].unique().tolist() if 'tic' in df.columns else []\n",
    "    print(\"Inferred assets:\", ASSETS[:10], \" (total\", len(ASSETS), \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63efb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature engineering (vectorized)\n",
    "def add_features(df):\n",
    "    # Assumes df has columns: date, tic, close, volume (optionally vix, turbulence)\n",
    "    out = df.copy()\n",
    "    out['return_1'] = out.groupby('tic')['close'].pct_change().fillna(0)\n",
    "    out['return_5'] = out.groupby('tic')['close'].pct_change(5).fillna(0)\n",
    "    out['ma_5'] = out.groupby('tic')['close'].transform(lambda x: x.rolling(5, min_periods=1).mean())\n",
    "    out['ma_20'] = out.groupby('tic')['close'].transform(lambda x: x.rolling(20, min_periods=1).mean())\n",
    "    out['ma_diff_5_20'] = out['ma_5'] - out['ma_20']\n",
    "    out['zscore_20'] = out.groupby('tic')['close'].transform(lambda x: (x - x.rolling(20, min_periods=1).mean()) / (x.rolling(20, min_periods=1).std() + 1e-9))\n",
    "    out['vol_20'] = out.groupby('tic')['return_1'].transform(lambda x: x.rolling(20, min_periods=1).std())\n",
    "    # Optional: fill VIX/turbulence forward if present\n",
    "    if 'vix' in out.columns:\n",
    "        out['vix'] = out['vix'].fillna(method='ffill').fillna(0)\n",
    "    if 'turbulence' in out.columns:\n",
    "        out['turbulence'] = out['turbulence'].fillna(0)\n",
    "    return out\n",
    "\n",
    "df = add_features(df)\n",
    "print(\"Features added. Columns:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6020910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Market-neutral environment (continuous target weights per asset)\n",
    "class MarketNeutralEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    def __init__(self, df, assets, initial_cash=1_000_000, max_trade_amount=1.0,\n",
    "                 commission_rate=COMMISSION_RATE, slippage_coef=SLIPPAGE_COEF,\n",
    "                 exposure_penalty=EXPOSURE_PENALTY, turnover_penalty=TURNOVER_PENALTY,\n",
    "                 sharpe_window=SHARPE_WINDOW):\n",
    "        super(MarketNeutralEnv, self).__init__()\n",
    "        self.df = df.copy()\n",
    "        self.assets = assets\n",
    "        self.n_assets = len(assets)\n",
    "        self.initial_cash = initial_cash\n",
    "        self.max_trade_amount = max_trade_amount\n",
    "        self.commission_rate = commission_rate\n",
    "        self.slippage_coef = slippage_coef\n",
    "        self.exposure_penalty = exposure_penalty\n",
    "        self.turnover_penalty = turnover_penalty\n",
    "        self.sharpe_window = sharpe_window\n",
    "\n",
    "        # observation: for each asset: [close, ma_diff_5_20, zscore_20, vol_20], plus global vix, turbulence (if present)\n",
    "        obs_len = 4 * self.n_assets + 2\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(obs_len,), dtype=np.float32)\n",
    "        # continuous actions: target weight per asset in [-1,1]\n",
    "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(self.n_assets,), dtype=np.float32)\n",
    "\n",
    "        # internal state reset\n",
    "        self.reset()\n",
    "\n",
    "    def _get_row(self, idx):\n",
    "        # returns a dataframe slice at given time index (rows for all assets)\n",
    "        return self.df.iloc[idx*self.n_assets:(idx+1)*self.n_assets]\n",
    "\n",
    "    def reset(self):\n",
    "        # align data length to full steps\n",
    "        # compute number of time steps (assumes full panel: each timestamp has rows for all assets)\n",
    "        timestamps = self.df['date'].unique()\n",
    "        self.timestamps = np.sort(timestamps)\n",
    "        self.steps_total = len(self.timestamps)\n",
    "        self.current_step = 0\n",
    "        self.portfolio_value = self.initial_cash\n",
    "        self.current_weights = np.zeros(self.n_assets, dtype=np.float32)\n",
    "        self.position_value = np.zeros(self.n_assets, dtype=np.float32)\n",
    "        self.returns_window = []\n",
    "        return self._get_obs()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        # build observation vector for current_step\n",
    "        t = self.timestamps[self.current_step]\n",
    "        rows = self.df[self.df['date'] == t].set_index('tic').reindex(self.assets)\n",
    "        # if missing values, fill with zeros\n",
    "        closes = rows['close'].fillna(method='ffill').fillna(0).values\n",
    "        ma_diff = rows['ma_diff_5_20'].fillna(0).values\n",
    "        zscore = rows['zscore_20'].fillna(0).values\n",
    "        vol = rows['vol_20'].fillna(0).values\n",
    "        # global\n",
    "        vix = rows['vix'].iloc[0] if 'vix' in rows.columns else 0.0\n",
    "        turb = rows['turbulence'].iloc[0] if 'turbulence' in rows.columns else 0.0\n",
    "        obs = np.concatenate([closes, ma_diff, zscore, vol, np.array([vix, turb])])\n",
    "        return obs.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        # action: target weights in [-1,1] for each asset\n",
    "        action = np.clip(action, -1.0, 1.0)\n",
    "        prev_portfolio_value = self.portfolio_value\n",
    "        # price vector at current step\n",
    "        t = self.timestamps[self.current_step]\n",
    "        rows = self.df[self.df['date'] == t].set_index('tic').reindex(self.assets)\n",
    "        prices = rows['close'].fillna(method='ffill').fillna(0).values\n",
    "\n",
    "        # compute trade amounts (absolute USD)\n",
    "        target_values = action * self.portfolio_value  # target dollar allocation per asset (could scale differently)\n",
    "        current_values = self.current_weights * self.portfolio_value\n",
    "        trade_values = target_values - current_values\n",
    "        trade_sizes = np.abs(trade_values)\n",
    "\n",
    "        # execution cost: commission + slippage\n",
    "        commission = self.commission_rate * trade_sizes.sum()\n",
    "        # approximate slippage using volatility (use vol column)\n",
    "        vols = rows['vol_20'].fillna(0).values\n",
    "        slippage = (self.slippage_coef * trade_sizes * (vols + 1e-6)).sum()\n",
    "\n",
    "        execution_cost = commission + slippage\n",
    "\n",
    "        # PnL: change in price from current to next step (we assume immediate rebalancing at current price,\n",
    "        # then price move to next close will realize PnL)\n",
    "        # we need next prices; if at last step, no price change\n",
    "        if self.current_step + 1 < self.steps_total:\n",
    "            t_next = self.timestamps[self.current_step + 1]\n",
    "            rows_next = self.df[self.df['date'] == t_next].set_index('tic').reindex(self.assets)\n",
    "            prices_next = rows_next['close'].fillna(method='ffill').fillna(0).values\n",
    "            returns = (prices_next - prices) / (prices + 1e-9)\n",
    "        else:\n",
    "            returns = np.zeros_like(prices)\n",
    "\n",
    "        # update holdings to target\n",
    "        self.current_weights = target_values / (self.portfolio_value + 1e-9)\n",
    "        # compute pnl from returns on target weights\n",
    "        pnl = (self.current_weights * returns).sum() * self.portfolio_value\n",
    "\n",
    "        # update portfolio value\n",
    "        self.portfolio_value = self.portfolio_value + pnl - execution_cost\n",
    "\n",
    "        # compute reward: raw return minus exposure_penalty and turnover penalty\n",
    "        ret = (self.portfolio_value - prev_portfolio_value) / (prev_portfolio_value + 1e-9)\n",
    "        net_exposure = np.abs(self.current_weights).sum()\n",
    "        exposure_penalty = self.exposure_penalty * net_exposure\n",
    "        turnover = trade_sizes.sum() / (self.portfolio_value + 1e-9)\n",
    "        turnover_pen = self.turnover_penalty * turnover\n",
    "\n",
    "        # rolling sharpe proxy\n",
    "        self.returns_window.append(ret)\n",
    "        if len(self.returns_window) > self.sharpe_window:\n",
    "            self.returns_window.pop(0)\n",
    "        if len(self.returns_window) >= max(5, int(self.sharpe_window/10)):\n",
    "            mean_r = np.mean(self.returns_window)\n",
    "            std_r = np.std(self.returns_window) + 1e-9\n",
    "            sharpe_proxy = mean_r / std_r\n",
    "            reward = sharpe_proxy - exposure_penalty - turnover_pen\n",
    "        else:\n",
    "            reward = ret - exposure_penalty - turnover_pen\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= self.steps_total - 1\n",
    "        info = {'pnl': pnl, 'execution_cost': execution_cost, 'net_exposure': net_exposure, 'portfolio_value': self.portfolio_value}\n",
    "\n",
    "        obs = self._get_obs() if not done else np.zeros(self.observation_space.shape, dtype=np.float32)\n",
    "        return obs, float(reward), bool(done), info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        print(f\"Step {self.current_step} PV={self.portfolio_value:.2f} weights_mean={self.current_weights.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448acba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Walk-forward training & evaluation utilities\n",
    "def make_env_from_df(df_slice, assets):\n",
    "    # df_slice must contain rows for consecutive timestamps for all assets\n",
    "    return MarketNeutralEnv(df_slice, assets)\n",
    "\n",
    "def evaluate_model_on_df(model, df_test, assets):\n",
    "    env = MarketNeutralEnv(df_test, assets)\n",
    "    obs = env.reset()\n",
    "    done=False\n",
    "    history = []\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        history.append(info)\n",
    "    # Collect metrics\n",
    "    pv = history[-1]['portfolio_value'] if history else env.portfolio_value\n",
    "    returns = [h.get('pnl',0)/ (env.initial_cash+1e-9) for h in history]\n",
    "    cum_return = pv / env.initial_cash - 1.0\n",
    "    # Rough annualized approx (requires timestamps frequency; skipped here) - return cum_return for now\n",
    "    return {'cumulative_return': cum_return, 'history': history}\n",
    "\n",
    "def walk_forward_train(df, assets, train_months=TRAIN_WINDOW_MONTHS, val_months=VAL_MONTHS, test_months=TEST_MONTHS):\n",
    "    results = []\n",
    "    timestamps = np.sort(df['date'].unique())\n",
    "    start = timestamps[0]\n",
    "    end = timestamps[-1]\n",
    "    cur_train_start = pd.to_datetime(start)\n",
    "    while True:\n",
    "        train_end = cur_train_start + pd.DateOffset(months=train_months)\n",
    "        val_end = train_end + pd.DateOffset(months=val_months)\n",
    "        test_end = val_end + pd.DateOffset(months=test_months)\n",
    "        if test_end > pd.to_datetime(end):\n",
    "            break\n",
    "        df_train = df[(df['date'] >= cur_train_start) & (df['date'] < train_end)].reset_index(drop=True)\n",
    "        df_val = df[(df['date'] >= train_end) & (df['date'] < val_end)].reset_index(drop=True)\n",
    "        df_test = df[(df['date'] >= val_end) & (df['date'] < test_end)].reset_index(drop=True)\n",
    "        print(f\"WF window: train {cur_train_start.date()} -> {train_end.date()}, test {val_end.date()} -> {test_end.date()}\")\n",
    "        env_train = DummyVecEnv([lambda: MarketNeutralEnv(df_train, assets)])\n",
    "        # optional normalization\n",
    "        try:\n",
    "            env_train = VecNormalize(env_train, norm_obs=True, norm_reward=False, clip_obs=10.0)\n",
    "        except Exception as e:\n",
    "            print(\"VecNormalize not available or failed:\", e)\n",
    "        model = SAC('MlpPolicy', env_train, **SAC_PARAMS)\n",
    "        model.learn(total_timesteps=TOTAL_TIMESTEPS)\n",
    "        # save model\n",
    "        model_path = os.path.join(OUTPUT_DIR, f\"sac_model_{cur_train_start.date()}_{test_end.date()}.zip\")\n",
    "        model.save(model_path)\n",
    "        # evaluate\n",
    "        perf = evaluate_model_on_df(model, df_test, assets)\n",
    "        perf['model_path'] = model_path\n",
    "        results.append(perf)\n",
    "        # roll forward by test_months\n",
    "        cur_train_start += pd.DateOffset(months=test_months)\n",
    "    # save results\n",
    "    with open(os.path.join(OUTPUT_DIR, 'walk_forward_results.json'), 'w') as f:\n",
    "        json.dump(results, f, default=str)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869dcd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run the walk-forward training (this may take a long time; adjust TOTAL_TIMESTEPS)\n",
    "# Ensure assets are a complete list covering df timestamps\n",
    "if len(ASSETS)==0:\n",
    "    ASSETS = df['tic'].unique().tolist()\n",
    "results = walk_forward_train(df, ASSETS)\n",
    "print(\"Walk-forward finished. Results:\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330808d8",
   "metadata": {},
   "source": [
    "\n",
    "# Final notes and next steps\n",
    "\n",
    "- Если хочешь ускорить тестирование — уменьш TOTAL_TIMESTEPS и/или сократи train/test окна.\n",
    "- Подумай об увеличении разнообразия данных (несколько лет) или data augmentation (noise/bootstrap) если переживаешь о смещении.\n",
    "- После получения моделей — проведи более строгую оценку: annualized metrics, sharpe, drawdown, bootstrap p-values.\n",
    "\n",
    "**Файлы, созданные этим ноутбуком:** модели `.zip` в `OUTPUT_DIR` и `walk_forward_results.json`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
