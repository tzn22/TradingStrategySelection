{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trading Environment for Stock Trading\n",
        "\n",
        "Gymnasium environment for RL-based stock trading with buy/sell/hold actions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple, Dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TradingEnv Class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TradingEnv class defined\n"
          ]
        }
      ],
      "source": [
        "class TradingEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    Trading environment for single stock trading.\n",
        "    \n",
        "    Actions: 0=Hold, 1=Buy (all-in), 2=Sell (all-out)\n",
        "    Reward: Sharpe ratio (return / risk)\n",
        "    \"\"\"\n",
        "    \n",
        "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 4}\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        data_path: str,\n",
        "        initial_balance: float = 10000.0,\n",
        "        lookback_window: int = 30,\n",
        "        render_mode: Optional[str] = None\n",
        "    ):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.initial_balance = initial_balance\n",
        "        self.lookback_window = lookback_window\n",
        "        self.render_mode = render_mode\n",
        "        \n",
        "        # Load data\n",
        "        self.data = self._load_data(data_path)\n",
        "        self.data_length = len(self.data)\n",
        "        \n",
        "        # Trading state\n",
        "        self.current_step = 0\n",
        "        self.balance = initial_balance\n",
        "        self.shares = 0\n",
        "        self.position = 0  # 0: no position, 1: long position\n",
        "        self.entry_price = 0.0\n",
        "        \n",
        "        # Track returns for Sharpe ratio\n",
        "        self.returns_history = []\n",
        "        self.portfolio_values = []\n",
        "        \n",
        "        # Action space: 0=hold, 1=buy, 2=sell\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "        \n",
        "        # Observation space: normalized prices, volume, returns, position info\n",
        "        n_features = 8\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf,\n",
        "            high=np.inf,\n",
        "            shape=(lookback_window, n_features),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        \n",
        "        # Normalization parameters\n",
        "        self.price_mean = None\n",
        "        self.price_std = None\n",
        "        self.volume_mean = None\n",
        "        self.volume_std = None\n",
        "        \n",
        "        self._compute_normalization_params()\n",
        "    \n",
        "    def _load_data(self, data_path: str) -> pd.DataFrame:\n",
        "        \"\"\"Load and preprocess stock data.\"\"\"\n",
        "        df = pd.read_csv(data_path, sep=',')\n",
        "        df['Date'] = pd.to_datetime(df['Date'])\n",
        "        df = df.sort_values('Date').reset_index(drop=True)\n",
        "        df['Returns'] = df['Close'].pct_change().fillna(0)\n",
        "        return df\n",
        "    \n",
        "    def _compute_normalization_params(self):\n",
        "        \"\"\"Compute normalization parameters from data.\"\"\"\n",
        "        self.price_mean = self.data[['Close', 'Open', 'High', 'Low']].mean().mean()\n",
        "        self.price_std = self.data[['Close', 'Open', 'High', 'Low']].std().mean()\n",
        "        self.volume_mean = self.data['Volume'].mean()\n",
        "        self.volume_std = self.data['Volume'].std()\n",
        "    \n",
        "    def reset(\n",
        "        self,\n",
        "        seed: Optional[int] = None,\n",
        "        options: Optional[dict] = None\n",
        "    ) -> Tuple[np.ndarray, Dict]:\n",
        "        \"\"\"Reset environment to initial state.\"\"\"\n",
        "        super().reset(seed=seed)\n",
        "        \n",
        "        # Start from a random point\n",
        "        self.current_step = np.random.randint(\n",
        "            self.lookback_window,\n",
        "            self.data_length - 100\n",
        "        )\n",
        "        \n",
        "        # Reset trading state\n",
        "        self.balance = self.initial_balance\n",
        "        self.shares = 0\n",
        "        self.position = 0\n",
        "        self.entry_price = 0.0\n",
        "        self.returns_history = []\n",
        "        self.portfolio_values = [self.initial_balance]\n",
        "        self._recent_actions = []\n",
        "        \n",
        "        observation = self._get_observation()\n",
        "        info = self._get_info()\n",
        "        \n",
        "        return observation, info\n",
        "    \n",
        "    def step(self, action: int) -> Tuple[np.ndarray, float, bool, bool, Dict]:\n",
        "        \"\"\"Execute one step in the environment.\"\"\"\n",
        "        self._execute_action(action)\n",
        "        self.current_step += 1\n",
        "        \n",
        "        terminated = self.current_step >= self.data_length - 1\n",
        "        truncated = False\n",
        "        \n",
        "        reward = self._calculate_reward()\n",
        "        observation = self._get_observation()\n",
        "        info = self._get_info()\n",
        "        \n",
        "        return observation, reward, terminated, truncated, info\n",
        "    \n",
        "    def _execute_action(self, action: int):\n",
        "        \"\"\"Execute trading action.\"\"\"\n",
        "        current_price = self.data.iloc[self.current_step]['Close']\n",
        "        \n",
        "        if action == 1:  # Buy\n",
        "            if self.position == 0:\n",
        "                self.shares = self.balance / current_price\n",
        "                self.balance = 0\n",
        "                self.position = 1\n",
        "                self.entry_price = current_price\n",
        "                \n",
        "        elif action == 2:  # Sell\n",
        "            if self.position == 1:\n",
        "                self.balance = self.shares * current_price\n",
        "                self.shares = 0\n",
        "                self.position = 0\n",
        "                self.entry_price = 0.0\n",
        "        \n",
        "        # Track recent actions\n",
        "        if not hasattr(self, '_recent_actions'):\n",
        "            self._recent_actions = []\n",
        "        self._recent_actions.append(action)\n",
        "        if len(self._recent_actions) > 10:\n",
        "            self._recent_actions.pop(0)\n",
        "    \n",
        "    def _get_portfolio_value(self) -> float:\n",
        "        \"\"\"Calculate current portfolio value.\"\"\"\n",
        "        if self.current_step >= len(self.data):\n",
        "            current_price = self.data.iloc[-1]['Close']\n",
        "        else:\n",
        "            current_price = self.data.iloc[self.current_step]['Close']\n",
        "        return self.balance + self.shares * current_price\n",
        "    \n",
        "    def _calculate_reward(self) -> float:\n",
        "        \"\"\"Calculate reward based on Sharpe ratio.\"\"\"\n",
        "        current_value = self._get_portfolio_value()\n",
        "        self.portfolio_values.append(current_value)\n",
        "        \n",
        "        # Calculate returns\n",
        "        if len(self.portfolio_values) > 1:\n",
        "            daily_return = (current_value - self.portfolio_values[-2]) / self.portfolio_values[-2]\n",
        "            self.returns_history.append(daily_return)\n",
        "        \n",
        "        # Early reward\n",
        "        if len(self.returns_history) < 2:\n",
        "            if len(self.returns_history) == 1:\n",
        "                return self.returns_history[0] * 10\n",
        "            return 0.0\n",
        "        \n",
        "        returns_array = np.array(self.returns_history)\n",
        "        mean_return = np.mean(returns_array)\n",
        "        std_return = np.std(returns_array)\n",
        "        \n",
        "        if std_return < 1e-8:\n",
        "            return mean_return * 100\n",
        "        \n",
        "        # Sharpe ratio\n",
        "        sharpe_ratio = mean_return / std_return\n",
        "        recent_return = self.returns_history[-1] if self.returns_history else 0.0\n",
        "        \n",
        "        # Weighted reward: 70% Sharpe ratio, 30% recent return\n",
        "        reward = (sharpe_ratio * 0.7 + recent_return * 10 * 0.3) * 0.1\n",
        "        \n",
        "        # Penalty for holding cash too long\n",
        "        if self.position == 0 and len(self.returns_history) > 10:\n",
        "            recent_actions = getattr(self, '_recent_actions', [])\n",
        "            if len(recent_actions) > 5 and all(a == 0 for a in recent_actions[-5:]):\n",
        "                reward -= 0.001\n",
        "        \n",
        "        return reward\n",
        "    \n",
        "    def _get_observation(self) -> np.ndarray:\n",
        "        \"\"\"Get current observation.\"\"\"\n",
        "        start_idx = max(0, self.current_step - self.lookback_window + 1)\n",
        "        end_idx = self.current_step + 1\n",
        "        \n",
        "        window_data = self.data.iloc[start_idx:end_idx].copy()\n",
        "        \n",
        "        # Pad if necessary\n",
        "        if len(window_data) < self.lookback_window:\n",
        "            padding = self.lookback_window - len(window_data)\n",
        "            first_row = window_data.iloc[0:1]\n",
        "            padding_data = pd.concat([first_row] * padding, ignore_index=True)\n",
        "            window_data = pd.concat([padding_data, window_data], ignore_index=True)\n",
        "        \n",
        "        # Normalize features\n",
        "        normalized_close = (window_data['Close'] - self.price_mean) / (self.price_std + 1e-8)\n",
        "        normalized_open = (window_data['Open'] - self.price_mean) / (self.price_std + 1e-8)\n",
        "        normalized_high = (window_data['High'] - self.price_mean) / (self.price_std + 1e-8)\n",
        "        normalized_low = (window_data['Low'] - self.price_mean) / (self.price_std + 1e-8)\n",
        "        normalized_volume = (window_data['Volume'] - self.volume_mean) / (self.volume_std + 1e-8)\n",
        "        returns = window_data['Returns'].values\n",
        "        position_indicator = np.full(self.lookback_window, self.position)\n",
        "        cash_ratio = (self.balance / self.initial_balance) * np.ones(self.lookback_window)\n",
        "        \n",
        "        # Stack features\n",
        "        observation = np.column_stack([\n",
        "            normalized_close.values,\n",
        "            normalized_open.values,\n",
        "            normalized_high.values,\n",
        "            normalized_low.values,\n",
        "            normalized_volume.values,\n",
        "            returns,\n",
        "            position_indicator,\n",
        "            cash_ratio\n",
        "        ]).astype(np.float32)\n",
        "        \n",
        "        return observation\n",
        "    \n",
        "    def _get_info(self) -> Dict:\n",
        "        \"\"\"Get additional information about current state.\"\"\"\n",
        "        return {\n",
        "            \"step\": self.current_step,\n",
        "            \"balance\": self.balance,\n",
        "            \"shares\": self.shares,\n",
        "            \"position\": self.position,\n",
        "            \"portfolio_value\": self._get_portfolio_value(),\n",
        "            \"current_price\": self.data.iloc[self.current_step]['Close']\n",
        "        }\n",
        "    \n",
        "    def render(self):\n",
        "        \"\"\"Render environment.\"\"\"\n",
        "        if self.render_mode == \"human\":\n",
        "            info = self._get_info()\n",
        "            print(f\"Step: {info['step']}, \"\n",
        "                  f\"Portfolio: ${info['portfolio_value']:.2f}, \"\n",
        "                  f\"Position: {info['position']}, \"\n",
        "                  f\"Price: ${info['current_price']:.2f}\")\n",
        "\n",
        "print(\"TradingEnv class defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using: iba.us.txt\n",
            "\n",
            "Environment created:\n",
            "  Action space: Discrete(3)\n",
            "  Observation space: (30, 8)\n",
            "  Data length: 3199\n",
            "\n",
            "Reset:\n",
            "  Observation shape: (30, 8)\n",
            "  Step: 483, Portfolio: $10000.00\n",
            "\n",
            "Testing actions:\n",
            "  After BUY: Portfolio=$9816.75, Position=1, Shares=424.20\n",
            "  After HOLD: Portfolio=$9899.47, Position=1\n",
            "  After SELL: Portfolio=$9899.47, Position=0, Balance=$9899.47\n",
            "\n",
            "Environment test completed!\n"
          ]
        }
      ],
      "source": [
        "# Find a data file\n",
        "data_dir = Path('data')\n",
        "data_files = list(data_dir.rglob('*.txt'))\n",
        "\n",
        "if not data_files:\n",
        "    print(\"No data files found!\")\n",
        "else:\n",
        "    test_file = data_files[0]\n",
        "    print(f\"Using: {test_file.name}\")\n",
        "    \n",
        "    # Create environment\n",
        "    env = TradingEnv(\n",
        "        data_path=str(test_file),\n",
        "        initial_balance=10000.0,\n",
        "        lookback_window=30,\n",
        "        render_mode=\"human\"\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nEnvironment created:\")\n",
        "    print(f\"  Action space: {env.action_space}\")\n",
        "    print(f\"  Observation space: {env.observation_space.shape}\")\n",
        "    print(f\"  Data length: {env.data_length}\")\n",
        "    \n",
        "    # Test reset\n",
        "    observation, info = env.reset()\n",
        "    print(f\"\\nReset:\")\n",
        "    print(f\"  Observation shape: {observation.shape}\")\n",
        "    print(f\"  Step: {info['step']}, Portfolio: ${info['portfolio_value']:.2f}\")\n",
        "    \n",
        "    # Test actions\n",
        "    print(f\"\\nTesting actions:\")\n",
        "    \n",
        "    # Buy\n",
        "    observation, reward, _, _, info = env.step(1)\n",
        "    print(f\"  After BUY: Portfolio=${info['portfolio_value']:.2f}, Position={info['position']}, Shares={info['shares']:.2f}\")\n",
        "    \n",
        "    # Hold\n",
        "    observation, reward, _, _, info = env.step(0)\n",
        "    print(f\"  After HOLD: Portfolio=${info['portfolio_value']:.2f}, Position={info['position']}\")\n",
        "    \n",
        "    # Sell\n",
        "    observation, reward, _, _, info = env.step(2)\n",
        "    print(f\"  After SELL: Portfolio=${info['portfolio_value']:.2f}, Position={info['position']}, Balance=${info['balance']:.2f}\")\n",
        "    \n",
        "    print(\"\\nEnvironment test completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example: Random Agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running random agent for 200 steps...\n",
            "After reset: Portfolio=$10000.00, Position=0\n",
            "\n",
            "Step 0: Portfolio=$10000.00, Position=0, Reward=0.0000\n",
            "Step 50: Portfolio=$9642.79, Position=0, Reward=-0.0045\n",
            "Step 100: Portfolio=$8609.11, Position=0, Reward=-0.0086\n",
            "Step 150: Portfolio=$4902.87, Position=1, Reward=-0.0153\n",
            "\n",
            "Results:\n",
            "  Initial balance: $10000.00\n",
            "  Final portfolio value: $5748.23\n",
            "  Total return: -42.52%\n",
            "  Total reward: -1.9015\n"
          ]
        }
      ],
      "source": [
        "# Create environment\n",
        "if 'env' not in locals():\n",
        "    data_file = data_files[0]\n",
        "    env = TradingEnv(\n",
        "        data_path=str(data_file),\n",
        "        initial_balance=10000.0,\n",
        "        lookback_window=30\n",
        "    )\n",
        "\n",
        "# Run random agent\n",
        "observation, info = env.reset()\n",
        "total_reward = 0\n",
        "\n",
        "print(\"Running random agent for 200 steps...\")\n",
        "print(f\"After reset: Portfolio=${info['portfolio_value']:.2f}, Position={info['position']}\\n\")\n",
        "\n",
        "for step in range(200):\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, terminated, truncated, info = env.step(action)\n",
        "    total_reward += reward\n",
        "    \n",
        "    if step % 50 == 0:\n",
        "        print(f\"Step {step}: Portfolio=${info['portfolio_value']:.2f}, \"\n",
        "              f\"Position={info['position']}, Reward={reward:.4f}\")\n",
        "    \n",
        "    if terminated or truncated:\n",
        "        print(f\"\\nEpisode ended at step {step}\")\n",
        "        break\n",
        "\n",
        "print(f\"\\nResults:\")\n",
        "print(f\"  Initial balance: ${env.initial_balance:.2f}\")\n",
        "print(f\"  Final portfolio value: ${info['portfolio_value']:.2f}\")\n",
        "print(f\"  Total return: {(info['portfolio_value'] / env.initial_balance - 1) * 100:.2f}%\")\n",
        "print(f\"  Total reward: {total_reward:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
